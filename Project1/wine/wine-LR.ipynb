{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_data(file_path, delimiter, skiprows=0):\n",
    "    \"\"\"loads a data file and returns a numpy array\"\"\"\n",
    "    file = open(file_path, \"rb\")\n",
    "    arr = np.loadtxt(file, delimiter=delimiter, skiprows=skiprows)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"winequality-red.csv\", \";\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    row[-1] = 0 if row[-1] <= 5 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[:,1:-1]\n",
    "Y=np.ravel((data[:,-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = true labels\n",
    "# y_hat = training labels\n",
    "# return: accuracy of training labels (in percentage)\n",
    "# Ensure that y and y_hat contain the labels for the same training examples.\n",
    "def evaluate_acc(y, y_hat):\n",
    "    score = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == y_hat[i]:\n",
    "            score += 1\n",
    "    return (score / y.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = class labels of training examples\n",
    "# x = feature data of training examples\n",
    "# 2 < k = number of folds to use in validation\n",
    "# return: average of prediction error over the k rounds of execution\n",
    "def k_fold(x, y, k, model):\n",
    "    if k < 1:\n",
    "        return \"Must have at least 1 fold.\"\n",
    "    elif k > (x.shape[0]//2):\n",
    "        return \"Too many folds.\"\n",
    "    elif k == 1:\n",
    "        print(\"1 fold selected - model will be trained and validated on same data set\")\n",
    "        model.fit(x, y)\n",
    "        return evaluate_acc(y, model.predict(x))\n",
    "    else:\n",
    "        rows_per_fold = (x.shape[0] + 1)//k       # a few rows at the end of the training data will be unused\n",
    "        accuracy = 0\n",
    "\n",
    "        for exec_round in range(k):\n",
    "            # determine held-out range\n",
    "            lower_row = exec_round * rows_per_fold\n",
    "            upper_row = ((exec_round + 1) * rows_per_fold) - 1\n",
    "            \n",
    "            # create validation set\n",
    "            x_val = np.copy(x)[lower_row:upper_row]\n",
    "            y_val = np.copy(y)[lower_row:upper_row]\n",
    "\n",
    "            # create training set\n",
    "            x_trn = np.concatenate((x[0:lower_row], x[upper_row:]))\n",
    "            y_trn = np.concatenate((y[0:lower_row], y[upper_row:]))\n",
    "\n",
    "            # train model\n",
    "            model.fit(x_trn, y_trn)\n",
    "\n",
    "            # run validation set through model\n",
    "            y_hat = model.predict(x_val)\n",
    "            accuracy += evaluate_acc(y_val, y_hat)\n",
    "\n",
    "        return accuracy / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, alpha=0.0001, threshold = 1.5):\n",
    "        self.alpha = alpha\n",
    "        self.threshold = threshold\n",
    "        self.stop = False\n",
    "        self.weights = None\n",
    "        self.max_iter = 10000\n",
    "        self.change = []\n",
    "\n",
    "    def __intercept(self, X):\n",
    "        return np.c_[np.ones(len(X)), X]\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def __grad(self, X_i, y_i):\n",
    "        z = np.dot(self.weights.T, X_i)\n",
    "        return X_i*(y_i-self.__sigmoid(z))\n",
    "    \n",
    "    def __update(self, X, Y):\n",
    "        changeW = np.zeros(np.size(X, 1))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            grad = self.__grad(X[i], Y[i])\n",
    "            changeW = changeW + self.alpha*grad\n",
    "#         print(np.linalg.norm(changeW))\n",
    "        self.change.append(np.linalg.norm(changeW))\n",
    "        self.weights = self.weights + changeW\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.change = [] # reset the gradients before running a new fit\n",
    "        padded_X = self.__intercept(X)\n",
    "        self.weights = np.zeros(np.size(padded_X,1))\n",
    "        \n",
    "        num_iter = 0\n",
    "        while len(self.change) < 1000 or self.change[-1] > self.threshold and num_iter < self.max_iter:\n",
    "            self.__update(padded_X, Y)\n",
    "            num_iter+=1\n",
    "            \n",
    "            if (num_iter == self.max_iter):\n",
    "                print(f\"Warning, reached max iterations of {self.max_iter}, stopping because we haven't converged yet\")\n",
    "                break\n",
    "\n",
    "        print(f\"learning rate:{self.alpha} \\n stop threshold:{self.threshold} \\n number of iterations: {num_iter}\")\n",
    "        print(f\"weights:{self.weights}\")\n",
    "        \n",
    "        return self.weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        padded_X = self.__intercept(X)\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(0, len(X)):\n",
    "            Z = np.dot(self.weights.T, padded_X[i])\n",
    "            pred = self.__sigmoid(Z).round()\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold selected - model will be trained and validated on same data set\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-15.24983136 -38.04730747  12.00555257  -3.10866986  -4.13019368\n",
      "   4.2747384   -0.69117553 -15.25897934 -51.49106061  17.73269461\n",
      "  23.95367676]\n",
      "1-fold LR accuracy on wine: 55.03439649781113\n",
      "78.7933897972107\n",
      "\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[ -9.14381698 -20.24417875   6.42947943  -1.7749464   -2.53879864\n",
      "   2.22445449  -1.69221344  -9.18892192 -30.02532272   7.73061983\n",
      "  12.23776707]\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 1001\n",
      "weights:[-0.64057538 -2.11536929  0.93761563  0.28294807 -0.12684089  1.84790407\n",
      " -0.56727772 -0.63745016 -2.29156225  1.11698343  3.41069503]\n",
      "2-fold LR accuracy on wine: 59.449311639549435\n",
      "43.21233296394348\n",
      "\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-11.78451349 -27.79075945   6.12768914  -3.98532882  -2.46158719\n",
      "   3.4223712   -0.58011494 -11.87013325 -37.4016637   12.41096462\n",
      "  17.01052067]\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-10.29947964 -27.02034818  10.08363499  -2.35550954  -3.56033107\n",
      "   3.66146664  -0.843828   -10.24996375 -33.9409426   12.16877794\n",
      "  16.34039639]\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 1000\n",
      "weights:[-1.13676814 -2.83686973  1.2606396   0.38676709 -0.23469241  2.09145672\n",
      " -0.95342707 -1.1385287  -4.18864454  1.11906668  3.81854556]\n",
      "3-fold LR accuracy on wine: 59.523809523809526\n",
      "111.6887936592102\n",
      "\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-12.91457881 -30.18351555   8.80395937  -4.3325989   -2.56036441\n",
      "   3.82341332  -0.69759301 -12.96703179 -42.33075593  13.92416579\n",
      "  19.28552673]\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-11.67017298 -28.70722758   9.77142072  -1.87074915  -4.1562658\n",
      "   4.07214299  -0.78512382 -11.66886984 -39.42635287  11.34386909\n",
      "  17.83489785]\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 1002\n",
      "weights:[-1.24296688 -3.43034531  1.41480829 -0.05097332 -0.25146688  1.35987272\n",
      " -1.52127099 -1.24172289 -4.14424383  1.69183508  4.07331643]\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-10.15886449 -26.99073497   9.44064242  -2.2975582   -2.9242994\n",
      "   3.81291197  -0.85973204 -10.15986247 -37.06652821  11.27242698\n",
      "  17.23773399]\n",
      "4-fold LR accuracy on wine: 56.015037593984964\n",
      "181.1219289302826\n",
      "\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-13.24761274 -32.14279675  11.21938728  -3.00757133  -2.6340311\n",
      "   3.33075108  -3.05525731 -13.27251471 -44.22926587  16.76452455\n",
      "  19.31787748]\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-13.02470657 -30.86055608   6.69455461  -3.58438774  -4.21966033\n",
      "   3.85901177  -0.91424924 -13.09241246 -41.09553823  11.37939882\n",
      "  19.26138971]\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-12.18451377 -31.35320322   9.8749851   -3.19760741  -3.84977661\n",
      "   3.71132221  -0.86513886 -12.15014235 -41.46072706  15.02191282\n",
      "  19.90603792]\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 1005\n",
      "weights:[-1.3922488  -3.61305295  1.65218249  0.47657148 -0.26576165  2.21242097\n",
      " -2.22035313 -1.39170369 -4.83326141  1.68820058  4.17268836]\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 7835\n",
      "weights:[ -9.57223975 -24.63445211   8.71603422  -3.18157925  -2.64695472\n",
      "   3.13515975  -2.46995858  -9.58248017 -34.32208688   9.90399594\n",
      "  16.38170204]\n",
      "5-fold LR accuracy on wine: 61.504702194357364\n",
      "244.55159974098206\n",
      "\n",
      "Warning, reached max iterations of 10000, stopping because we haven't converged yet\n",
      "learning rate:0.0001 \n",
      " stop threshold:1.5 \n",
      " number of iterations: 10000\n",
      "weights:[-13.28971088 -34.05486465  12.08575627  -3.03177041  -2.74261936\n",
      "   3.42771053  -3.19418595 -13.31085345 -44.82348703  17.59536105\n",
      "  19.78209816]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "lr = LogisticRegression()\n",
    "for i in range(1, 10):\n",
    "    startTime = time.time()\n",
    "    print(str(i) + \"-fold LR accuracy on wine: \" + str(k_fold(X, Y, i, lr)))\n",
    "    print(time.time() - startTime)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
