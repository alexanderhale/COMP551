{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Assumptions\n",
    "    - All preprocessing is completed and has been stored in a .csv file\n",
    "    - There exists no \"bad\" data such that an associated label is out of the labeled set\n",
    "    - The vectors placed into the training set are of the same form as the test set\n",
    "        - There exists no errors due to unseen words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic\n",
    "import os\n",
    "\n",
    "# Data management\n",
    "import csv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Deep learning \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Math and plots\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_MODEL = True\n",
    "TRAIN = True\n",
    "SPLIT_USE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "    - Assumes data is preprossessed such that no transformation must be done on load\n",
    "    - Does not load element as a tensor\n",
    "    - Return a descriptor vector and an encoded vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths\n",
    "train_data = './Data/name_of_train.csv'\n",
    "test_data = './Data/name_of_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader fir train and test\n",
    "class CommentData(Dataset):\n",
    "    \n",
    "    def __init__(self, frames):\n",
    "        self.frames = frames\n",
    "        self.labels = np.unique(self.frames)\n",
    "        self.encoding = np.eye(len(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        element, label = self.frames[idx]\n",
    "        enc_label = self.encode(label)\n",
    "        return element, enc_label\n",
    "    \n",
    "    # one-hot encoding on element fetch\n",
    "    def encode(self, label):\n",
    "        location = self.labels.index(label)\n",
    "        encoding = self.encoding[location]\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume loaded Nx1x1\n",
    "# leverages pandas for fast csv load but operates in numpy\n",
    "class kFold():\n",
    "    def __init__(self, filepath, numFolds=5):\n",
    "        self.data = np.asarray(pd.read_csv(csv_file))\n",
    "        self.numFolds = numFolds\n",
    "        self.splits = []\n",
    "        \n",
    "    def generateSplits(self):\n",
    "        np.random.shuffle(self.data)\n",
    "        \n",
    "        folds = []\n",
    "        splitPoint = self.data.shape[0] // (self.numFolds)  #breakpoint index jump\n",
    "        \n",
    "        for i in range(self.numFolds - 1):\n",
    "            folds.append(self.data[i*splitPoint:(i+1)*splitPoint, :, :])\n",
    "            \n",
    "        folds.append(self.data[(i+1)*splitPoint:,:,:]) #get extra points in last batch\n",
    "        \n",
    "        # create split permutations 80/10/10\n",
    "        foldDivisor = len(folds) // 2\n",
    "        for i in range(self.numFolds):\n",
    "            for k in range(self.numFolds):\n",
    "                if i == k:\n",
    "                    validation = fold[i][:foldDivisor] \n",
    "                    test = fold[i][foldDivisor:] \n",
    "                else:\n",
    "                    train.append(fold[k])\n",
    "            \n",
    "            train = np.hstack(train) # adapt dims\n",
    "            self.split.append((train, validation, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhoReddit(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WhoReddit, self).__init__()\n",
    "        \n",
    "        # mini inception net block 1\n",
    "        self.convA1 = nn.Conv1d(1, 64, 3, padding = 1)\n",
    "        self.normA1 = nn.BatchNorm1d(64)\n",
    "        self.reluA1 = nn.ReLU(True)\n",
    "        self.poolA1 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.convB1 = nn.Conv1d(1, 64, 5, padding = 2)\n",
    "        self.normB1 = nn.BatchNorm1d(64)\n",
    "        self.reluB1 = nn.ReLU(True)\n",
    "        self.poolB1 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.convC1 = nn.Conv1d(1, 64, 7, padding = 3)\n",
    "        self.normC1 = nn.BatchNorm1d(64)\n",
    "        self.reluC1 = nn.ReLU(True)\n",
    "        self.poolC1 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.blend1 = nn.Sequential(\n",
    "            nn.Conv1d(3*64, 96, 3, padding = 1)\n",
    "            nn.BatchNorm1d(96)\n",
    "            nn.Relu(True)\n",
    "            nn.MaxPool1d(3,3)\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # mini inception net block 2\n",
    "        self.convA2 = nn.Conv1d(96, 128, 3, padding = 1)\n",
    "        self.normA2 = nn.BatchNorm1d(128)\n",
    "        self.reluA2 = nn.ReLU(True)\n",
    "        self.poolA2 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.convB2 = nn.Conv1d(96, 128 5, padding = 2)\n",
    "        self.normB2 = nn.BatchNorm1d(128)\n",
    "        self.reluB2 = nn.ReLU(True)\n",
    "        self.poolB2 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.convC2 = nn.Conv1d(96, 128 7, padding = 3)\n",
    "        self.normC2 = nn.BatchNorm1d(128)\n",
    "        self.reluC2 = nn.ReLU(True)\n",
    "        self.poolC2 = nn.MaxPool1d(3, 3)\n",
    "    \n",
    "        self.blend2 = nn.Sequential(\n",
    "            nn.Conv1d(3*128, 196, 3, padding = 1)\n",
    "            nn.BatchNorm1d(196)\n",
    "            nn.Relu(True)\n",
    "            nn.MaxPool1d(3,3)\n",
    "        )\n",
    "        \n",
    "        # mini inception net block 3\n",
    "        self.convA3 = nn.Conv1d(196, 256, 3, padding = 1)\n",
    "        self.normA3 = nn.BatchNorm1d(128)\n",
    "        self.reluA3 = nn.ReLU(True)\n",
    "        self.poolA3 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        # core modules\n",
    "        self.convB3 = nn.Conv1d(196, 256, 5, padding = 2)\n",
    "        self.normB3 = nn.BatchNorm1d(128)\n",
    "        self.reluB3 = nn.ReLU(True)\n",
    "        self.poolB3 = nn.MaxPool1d(3, 3)\n",
    "        \n",
    "        self.convC3 = nn.Conv1d(196, 256, 7, padding = 3)\n",
    "        self.normC3 = nn.BatchNorm1d(128)\n",
    "        self.reluC3 = nn.ReLU(True)\n",
    "        self.poolC3 = nn.MaxPool1d(3, 3)\n",
    "    \n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Conv1d(3*196, 256, 3, padding = 1)\n",
    "            nn.BatchNorm1d(256)\n",
    "            nn.Relu(True)\n",
    "            nn.MaxPool1d(3,3)\n",
    "            nn.AdaptiveAvgPool1d(256)\n",
    "            nn.Dropout(0.2)\n",
    "            nn.Linear(256, 20)\n",
    "        )\n",
    "        \n",
    "        self.dropout = Dropout1d(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        A = self.dropout(self.poolA1(self.reluA1(self.normA1(self.convA1(x)))))\n",
    "        B = self.dropout(self.poolB1(self.reluB1(self.normB1(self.convB1(x)))))\n",
    "        C = self.dropout(self.poolC1(self.reluC1(self.normC1(self.convC1(x)))))\n",
    "        x = torch.cat((A,B,C), dim=1)\n",
    "        x = self.blend1(x)\n",
    "        \n",
    "        A = self.dropout(self.poolA2(self.reluA2(self.normA2(self.convA2(x)))))\n",
    "        B = self.dropout(self.poolB2(self.reluB2(self.normB2(self.convB2(x)))))\n",
    "        C = self.dropout(self.poolC2(self.reluC2(self.normC2(self.convC2(x)))))\n",
    "        x = torch.cat((A,B,C), dim=1)\n",
    "        x = self.blend2(x)\n",
    "        \n",
    "        A = self.dropout(self.poolA3(self.reluA3(self.normA3(self.convA3(x)))))\n",
    "        B = self.dropout(self.poolB3(self.reluB3(self.normB3(self.convB3(x)))))\n",
    "        C = self.dropout(self.poolC3(self.reluC3(self.normC3(self.convC3(x)))))\n",
    "        x = torch.cat((A,B,C), dim=1)\n",
    "        x = self.merge(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEW_MODEL:\n",
    "    net = WhoReddit()\n",
    "else:\n",
    "    #todo: load network\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss().type(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split init\n",
    "commentFolds = kFold(train_data) \n",
    "commentFolds.generateSplits()\n",
    "splits = commentFolds.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (train, validation, test) in enumerate(splits): # split\n",
    "    # Data loaders!!\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=2, num_workers=8, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(validation, batch_size=1, num_workers=8)\n",
    "    test_loader = torch.utils.data.DataLoader(validation, batch_size=1, num_workers=8)\n",
    "    \n",
    "    # train cycle here\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        \n",
    "        for i, (comment, label) in enumerate(train_loader):\n",
    "            \n",
    "            # tensor to device\n",
    "            comment = torch.FloatTensor(comment).to(device)\n",
    "            label = torch.FloatTensor(label).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = net(comment)\n",
    "            error = loss(output, label)\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:    # print every 50 mini-batches\n",
    "                print('[%d, %5d] loss: %.5f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 50))\n",
    "                running_loss = 0.0\n",
    "\n",
    "            # Get predictions\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            preds_cls = preds.argmax(dim=1)\n",
    "\n",
    "            # Count number of correct predictions\n",
    "            correct_preds = torch.eq(preds_cls, label)\n",
    "            correct += torch.sum(correct_preds).cpu().item()\n",
    "            total += len(correct_preds)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        print(\"Epoch:\", epoch+1,\"Training Acc:\",train_acc)\n",
    "\n",
    "        net.eval()\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        \n",
    "        for i, (comment, label) in enumerate(val_loader):\n",
    "\n",
    "            comment = torch.FloatTensor(comment).to(device)\n",
    "            label = torch.FloatTensor(label).to(device)\n",
    "            output = net(comment)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            preds_cls = preds.argmax(dim=1)\n",
    "\n",
    "            # Count number of correct predictions\n",
    "            correct_preds = torch.eq(preds_cls, label)\n",
    "            correct += torch.sum(correct_preds).cpu().item()\n",
    "            total += len(correct_preds)\n",
    "\n",
    "        valid_acc = correct / total\n",
    "        print(\"Epoch:\", epoch+1,\"Validation Acc:\",valid_acc)\n",
    "        \n",
    "        for i, (comment, label) in enumerate(test_loader):\n",
    "\n",
    "            comment = torch.FloatTensor(comment).to(device)\n",
    "            label = torch.FloatTensor(label).to(device)\n",
    "            output = net(comment)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            preds_cls = preds.argmax(dim=1)\n",
    "\n",
    "            # Count number of correct predictions\n",
    "            correct_preds = torch.eq(preds_cls, label)\n",
    "            correct += torch.sum(correct_preds).cpu().item()\n",
    "            total += len(correct_preds)\n",
    "\n",
    "        test_acc = correct / total\n",
    "        print(\"Epoch:\", epoch+1,\"Test Acc:\",test_acc)\n",
    "        \n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # terminate cycle\n",
    "    if idx-1 >= FOLD_USE:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
