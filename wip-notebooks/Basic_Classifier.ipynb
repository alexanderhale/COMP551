{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uN68430x71-g"
   },
   "source": [
    "Basic Neural Network Classifier for Modified MNist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TvQWyX1M71-i",
    "outputId": "0a147f37-04ca-4486-c8db-af0f9c4e3f12"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# Imports \n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgFsm9fPHv-W"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "-YeEfyh5Hpq5",
    "outputId": "14dd5d4d-f45a-4442-f653-8093e8c5c6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 16384)\n",
      "(10000, 16384)\n"
     ]
    }
   ],
   "source": [
    "og_trn_data = np.asarray(pd.read_pickle('train_max_x'))\n",
    "num_samples = og_trn_data.shape[0]\n",
    "num_features = og_trn_data.shape[1] * og_trn_data.shape[2]\n",
    "og_trn_data = og_trn_data.flatten().reshape(num_samples, num_features)\n",
    "print(og_trn_data.shape)\n",
    "\n",
    "og_trn_labels = pd.read_csv('train_max_y.csv')['Label'].to_numpy()\n",
    "\n",
    "og_test_data = np.asarray(pd.read_pickle('test_max_x'))\n",
    "num_samples = og_test_data.shape[0]\n",
    "num_features = og_test_data.shape[1] * og_test_data.shape[2]\n",
    "og_test_data = og_test_data.flatten().reshape(num_samples, num_features)\n",
    "print(og_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oureGhUIT5V"
   },
   "source": [
    "# Dataset Class\n",
    "Also includes a helper function to threshold the background out of the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFaQ0dNUIU6C"
   },
   "outputs": [],
   "source": [
    "def bwThresh(img):\n",
    "  threshold = 200\n",
    "  img[np.where(img < threshold)] = 0\n",
    "  return img\n",
    "\n",
    "class TrainingDataset(data.Dataset):\n",
    "  'Characterizes the training dataset.'\n",
    "  def __init__(self, transform=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        trn_file (string): Path to the zip file with training images.\n",
    "        label_file (string): Path to the csv file with labels.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "    \"\"\"\n",
    "    # currently loading all data into memory\n",
    "      # if that causes memory issues, will have \n",
    "      #   to load just a few point at a time\n",
    "    self.trn_data = og_trn_data\n",
    "    self.trn_labels = og_trn_labels\n",
    "    self.transform = transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    'Denotes the total number of samples'\n",
    "    return len(self.trn_labels)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    'Generates one sample of data'\n",
    "    # Select sample and its label\n",
    "    sample = self.trn_data[index]\n",
    "    label = self.trn_labels[index]\n",
    "\n",
    "    if self.transform:\n",
    "        sample = self.transform(sample)\n",
    "\n",
    "    return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hgCecJDIi8o"
   },
   "source": [
    "# Build Neural Network\n",
    "\n",
    "From tutorial. Should be replaced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rnAhgUlIr5t"
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \n",
    "        Args:\n",
    "            - D_in : input dimension of the data\n",
    "            - H : size of the first hidden layer\n",
    "            - D_out : size of the output/ second layer\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__() # intialize recursively \n",
    "        self.linear1 = torch.nn.Linear(D_in, H) # create a linear layer \n",
    "        self.linear2 = torch.nn.Linear(H, D_out) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data \n",
    "        and we must return a Variable of output data. We can use \n",
    "        Modules defined in the constructor as well as arbitrary \n",
    "        operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qgBYVkxIxym"
   },
   "source": [
    "# Instantiate the FNN\n",
    "Most of the hyperparameters (except the threshold level of the images) are within this section, so tweak them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvLScxMxI0_Y"
   },
   "outputs": [],
   "source": [
    "# create dataset and train-validation split\n",
    "dataset = TrainingDataset(transform=bwThresh)\n",
    "train_dataset, val_dataset = torch.utils.data.dataset.random_split(dataset, [45000, 5000])\n",
    "\n",
    "# create data loaders\n",
    "params = {'batch_size': 64, 'shuffle': True, 'num_workers': 0}\n",
    "train_loader = data.DataLoader(dataset=train_dataset, **params)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, **params)\n",
    "full_trn_loader = data.DataLoader(dataset=dataset, **params)\n",
    "\n",
    "# set size of neural network\n",
    "D_in = 128 * 128   # equal to input shape (128x128 grayscale image)\n",
    "H = 100            # TODO what should this be?\n",
    "D_out = 10         # equal to output shape (class 0 to 9)\n",
    "\n",
    "# instantiate neural network model\n",
    "model = TwoLayerNet(D_in, H, D_out) # TODO change inner-layer dimensions\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# set loss criteria and optimizer of the neural network\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "GFvwdomYdw7k",
    "outputId": "701c44db-fe5f-4283-d6b5-b073a879f225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss 11.922115543349223, validation loss 7.2329354950144324\n",
      "Epoch 1: training loss 3.6498066364702852, validation loss 4.033969058266169\n",
      "Epoch 2: training loss 2.3334708555855532, validation loss 3.6025947166394583\n",
      "Epoch 3: training loss 1.9152877911586652, validation loss 3.145274566698678\n",
      "Epoch 4: training loss 1.7170990783382545, validation loss 3.204611880869805\n",
      "Epoch 5: training loss 1.6013045575131069, validation loss 3.10971217819407\n",
      "Epoch 6: training loss 1.527493071149696, validation loss 3.218778601175622\n",
      "Epoch 7: training loss 1.4708385372703725, validation loss 3.0499460395378404\n",
      "Epoch 8: training loss 1.422461903061379, validation loss 3.2023018674005437\n",
      "Epoch 9: training loss 1.3822221806780859, validation loss 3.0982789842388296\n",
      "Epoch 10: training loss 1.3462094454602762, validation loss 3.4529406692408307\n",
      "Epoch 11: training loss 1.3191718748685988, validation loss 3.1445705015448073\n",
      "Epoch 12: training loss 1.2877127538350495, validation loss 3.186380615717248\n",
      "Epoch 13: training loss 1.2610973239114338, validation loss 3.2617588224290293\n",
      "Epoch 14: training loss 1.2383801760151982, validation loss 3.3021027166632155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahale\\Anaconda3\\envs\\mcgill-venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type TwoLayerNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\ahale\\Anaconda3\\envs\\mcgill-venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Training the FNN Model\n",
    "for epoch in range(15):\n",
    "    trn_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        # Transfer to GPU if possible\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = model(x)\n",
    "        # Computes loss\n",
    "        loss = criterion(yhat, y)\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # save the loss\n",
    "        trn_losses.append(loss.item())\n",
    "  \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            # Transfer to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            yhat = model(x)\n",
    "            val_losses.append(criterion(yhat, y).item())\n",
    "\n",
    "    print(\"Epoch {}: training loss {}, validation loss {}\".format(epoch, sum(trn_losses) / len(trn_losses), sum(val_losses) / len(val_losses)))\n",
    "\n",
    "torch.save(model.cpu(), \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SySjaMUR2xlH",
    "outputId": "9fafec69-6246-4ab4-9d91-c2fbe43d13d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "model = model.cpu()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in full_trn_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tutorial_Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
